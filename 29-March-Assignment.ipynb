{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6acb0e25-0e57-48c9-b20e-b13ea2319b62",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    " Lasso regression is a type of regression analysis that includes a penalty term to the sum of absolute values of the model's coefficients. \n",
    "         This encourages the model to reduce the magnitude of less important coefficients to zero, resulting in feature selection. \n",
    "         Lasso differs from other regression techniques like Ridge regression, which penalizes the sum of squared coefficients, and does not perform feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe98e0-f860-4ad4-a5e6-b9985ef9f9bc",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "Lasso regression can perform feature selection by shrinking the coefficients of less important features to zero. \n",
    "         This means that Lasso can identify the most important features for predicting the outcome variable and remove the less important ones, \n",
    "         which can improve the model's performance and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2c8e0-8c9b-44b1-b59a-cecf1aec69ab",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    " In Lasso regression, the coefficients represent the strength and direction of the relationship between the independent variables and the dependent variable. \n",
    "         A positive coefficient indicates a positive relationship, while a negative coefficient indicates a negative relationship. \n",
    "         The magnitude of the coefficient represents the strength of the relationship. The coefficients in Lasso regression can also be interpreted as feature \n",
    "         importance or feature selection, where variables with non-zero coefficients are considered important predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5aa4b-9952-4f76-b34f-0a251edf038f",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "In Lasso Regression, there is a tuning parameter called alpha that controls the strength of regularization. \n",
    "         A higher value of alpha results in a more restricted model with fewer features selected, while a lower value of alpha allows more features to be included in the model. \n",
    "         Thus, the choice of alpha should balance between model complexity and predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439afdda-8add-41d7-b6d3-08b6ce02ddf2",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "Lasso regression is primarily used for linear regression problems, but it can also be extended to non-linear regression problems by including non-linear transformations of the features. For example, polynomial regression can be combined with Lasso regularization to fit non-linear functions. However, this can increase the complexity of the model and the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10570b6b-b881-4e7c-b8bd-0530cb8a4c42",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    " Ridge and Lasso regression are two common techniques used in machine learning to reduce the impact of irrelevant or highly correlated features in a model. \n",
    "         Ridge regression shrinks the regression coefficients towards zero, while Lasso regression can shrink coefficients to exactly zero, effectively removing \n",
    "         features from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9fac6-79d7-4feb-9de0-e9991491a8bf",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features by introducing a penalty term that shrinks the regression coefficients towards zero, \n",
    "         effectively selecting only the most important features. This penalty term encourages the coefficients of correlated features to be close to each other or zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195b249-f32f-4667-9e67-640480a542c0",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    " To choose the optimal value of the regularization parameter lambda in Lasso Regression, one can use cross-validation to evaluate different values of lambda and \n",
    "         select the one that gives the best balance between model complexity and accuracy. Essentially, you want to find the value of lambda that minimizes the error of \n",
    "         the model while also preventing overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b8a8b-2bf6-4364-9640-9af0198dd182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
